{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./small_2015-06_key_word.csv\",index_col=False, header=None, names=['id','text','food','activity','label'])\n",
    "df2 = pd.read_csv(\"./small_2015-11_key_word.csv\",index_col=False, header=None, names=['id','text','food','activity','label'])\n",
    "df = pd.concat((df1,df2),axis=0)\n",
    "lst = []\n",
    "for i,sentence in enumerate(df['text']):\n",
    "    try:\n",
    "        if len(sentence.split(' ')) > 4:\n",
    "            lst.append(i)\n",
    "    except:\n",
    "        continue\n",
    "df = df.iloc[lst].replace(3,2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7316139, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed LDA's output into a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_lst = [\"./data/tfVectorizer_topics=25_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\", \"./data/tfVectorizer_topics=25_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\",\n",
    "          \"./data/tfVectorizer_topics=25_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\", \"./data/tfVectorizer_topics=25_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\",\n",
    "          \"./data/tfVectorizer_topics=25_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\", \"./data/tfVectorizer_topics=50_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\",\n",
    "          \"./data/tfVectorizer_topics=50_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\", \"./data/tfVectorizer_topics=50_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\",\n",
    "          \"./data/tfVectorizer_topics=75_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\", \"./data/tfVectorizer_topics=75_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\",\n",
    "          \"./data/tfVectorizer_topics=75_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\", \"./data/tfVectorizer_topics=75_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\",\n",
    "          \"./data/tfVectorizer_topics=75_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\", \"./data/tfVectorizer_topics=100_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\"]\n",
    "lda_lst = [\"./data/LDA_topics=25_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\", \"./data/LDA_topics=25_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\",\n",
    "           \"./data/LDA_topics=25_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\", \"./data/LDA_topics=25_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\",\n",
    "           \"./data/LDA_topics=25_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\", \"./data/LDA_topics=50_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\",\n",
    "           \"./data/LDA_topics=50_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\", \"./data/LDA_topics=50_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\",\n",
    "           \"./data/LDA_topics=75_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\", \"./data/LDA_topics=75_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\",\n",
    "           \"./data/LDA_topics=75_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\", \"./data/LDA_topics=75_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\",\n",
    "           \"./data/LDA_topics=75_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\", \"./data/LDA_topics=100_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/tfVectorizer_topics=25_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n",
      "./data/LDA_topics=25_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n",
      "Transform Time: 402.9718s\n",
      "Test Accuracy: 0.6044\n",
      "./data/tfVectorizer_topics=25_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\n",
      "./data/LDA_topics=25_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\n",
      "Transform Time: 394.3956s\n",
      "Test Accuracy: 0.6061\n",
      "./data/tfVectorizer_topics=25_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\n",
      "./data/LDA_topics=25_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\n",
      "Transform Time: 391.5192s\n",
      "Test Accuracy: 0.6097\n",
      "./data/tfVectorizer_topics=25_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\n",
      "./data/LDA_topics=25_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\n",
      "Transform Time: 389.5022s\n",
      "Test Accuracy: 0.5938\n",
      "./data/tfVectorizer_topics=25_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\n",
      "./data/LDA_topics=25_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\n",
      "Transform Time: 392.8519s\n",
      "Test Accuracy: 0.592\n",
      "./data/tfVectorizer_topics=50_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n",
      "./data/LDA_topics=50_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n",
      "Transform Time: 431.1828s\n",
      "Test Accuracy: 0.6153\n",
      "./data/tfVectorizer_topics=50_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\n",
      "./data/LDA_topics=50_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\n",
      "Transform Time: 438.838s\n",
      "Test Accuracy: 0.6081\n",
      "./data/tfVectorizer_topics=50_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\n",
      "./data/LDA_topics=50_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\n",
      "Transform Time: 421.8559s\n",
      "Test Accuracy: 0.6145\n",
      "./data/tfVectorizer_topics=75_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/LDA_topics=75_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n",
      "Transform Time: 484.2251s\n",
      "Test Accuracy: 0.6181\n",
      "./data/tfVectorizer_topics=75_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/LDA_topics=75_maxFeatures=12000_maxDf=0.5_minDf=1.pickle\n",
      "Transform Time: 483.2631s\n",
      "Test Accuracy: 0.6097\n",
      "./data/tfVectorizer_topics=75_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/LDA_topics=75_maxFeatures=12000_maxDf=0.6_minDf=1.pickle\n",
      "Transform Time: 480.1674s\n",
      "Test Accuracy: 0.6109\n",
      "./data/tfVectorizer_topics=75_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/LDA_topics=75_maxFeatures=16000_maxDf=0.4_minDf=1.pickle\n",
      "Transform Time: 487.3209s\n",
      "Test Accuracy: 0.6047\n",
      "./data/tfVectorizer_topics=75_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/ice/anaconda/lib/python3.5/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.20.dev0 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/LDA_topics=75_maxFeatures=16000_maxDf=0.5_minDf=1.pickle\n",
      "Transform Time: 487.4308s\n",
      "Test Accuracy: 0.6143\n",
      "./data/tfVectorizer_topics=100_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n",
      "./data/LDA_topics=100_maxFeatures=12000_maxDf=0.4_minDf=1.pickle\n",
      "Transform Time: 587.0208s\n",
      "Test Accuracy: 0.6269\n",
      "CPU times: user 2h 2min 53s, sys: 7min 3s, total: 2h 9min 57s\n",
      "Wall time: 2h 15min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc_lst = []\n",
    "for tf_name, lda_name in zip(*(tf_lst,lda_lst)):\n",
    "    # load tf_vectorizer and lda model\n",
    "    with open(tf_name, \"rb\") as input_file:\n",
    "        print(tf_name)\n",
    "        tf_vectorizer = pkl.load(input_file)\n",
    "    with open(lda_name, \"rb\") as input_file:\n",
    "        print(lda_name)\n",
    "        lda = pkl.load(input_file)\n",
    "        \n",
    "    # predicts probs of text using lda\n",
    "    start = time.time()\n",
    "    probs = lda.transform(tf_vectorizer.transform(df['text'].tolist()))\n",
    "    probs = pd.DataFrame(probs) \n",
    "    X = pd.concat((df,probs),axis=1)\n",
    "    print(\"Transform Time: {}s\".format(round(time.time()-start,4)))\n",
    "\n",
    "    # randomly sample a balanced dataset\n",
    "    X0 = X[X['label']==0].sample(X.groupby('label').size()[2])\n",
    "    X = pd.concat((X0,X[X['label']==2]),axis=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.iloc[:,5:],X['label'],test_size=0.33,random_state=42)\n",
    "\n",
    "    # train random forest\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "    model.fit(X_train,y_train)\n",
    "    acc = round(model.score(X_test,y_test),4)\n",
    "    acc_lst.append(acc)\n",
    "    print(\"Test Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lda model</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>topics=25_maxFeatures=12000_maxDf=0.4_minDf=1....</td>\n",
       "      <td>0.6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>topics=25_maxFeatures=12000_maxDf=0.5_minDf=1....</td>\n",
       "      <td>0.6061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>topics=25_maxFeatures=12000_maxDf=0.6_minDf=1....</td>\n",
       "      <td>0.6097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>topics=25_maxFeatures=16000_maxDf=0.4_minDf=1....</td>\n",
       "      <td>0.5938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>topics=25_maxFeatures=16000_maxDf=0.5_minDf=1....</td>\n",
       "      <td>0.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>topics=50_maxFeatures=12000_maxDf=0.4_minDf=1....</td>\n",
       "      <td>0.6153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>topics=50_maxFeatures=12000_maxDf=0.5_minDf=1....</td>\n",
       "      <td>0.6081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>topics=50_maxFeatures=16000_maxDf=0.4_minDf=1....</td>\n",
       "      <td>0.6145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>topics=75_maxFeatures=12000_maxDf=0.4_minDf=1....</td>\n",
       "      <td>0.6181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>topics=75_maxFeatures=12000_maxDf=0.5_minDf=1....</td>\n",
       "      <td>0.6097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>topics=75_maxFeatures=12000_maxDf=0.6_minDf=1....</td>\n",
       "      <td>0.6109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>topics=75_maxFeatures=16000_maxDf=0.4_minDf=1....</td>\n",
       "      <td>0.6047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>topics=75_maxFeatures=16000_maxDf=0.5_minDf=1....</td>\n",
       "      <td>0.6143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>topics=100_maxFeatures=12000_maxDf=0.4_minDf=1...</td>\n",
       "      <td>0.6269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lda model     acc\n",
       "0   topics=25_maxFeatures=12000_maxDf=0.4_minDf=1....  0.6044\n",
       "1   topics=25_maxFeatures=12000_maxDf=0.5_minDf=1....  0.6061\n",
       "2   topics=25_maxFeatures=12000_maxDf=0.6_minDf=1....  0.6097\n",
       "3   topics=25_maxFeatures=16000_maxDf=0.4_minDf=1....  0.5938\n",
       "4   topics=25_maxFeatures=16000_maxDf=0.5_minDf=1....  0.5920\n",
       "5   topics=50_maxFeatures=12000_maxDf=0.4_minDf=1....  0.6153\n",
       "6   topics=50_maxFeatures=12000_maxDf=0.5_minDf=1....  0.6081\n",
       "7   topics=50_maxFeatures=16000_maxDf=0.4_minDf=1....  0.6145\n",
       "8   topics=75_maxFeatures=12000_maxDf=0.4_minDf=1....  0.6181\n",
       "9   topics=75_maxFeatures=12000_maxDf=0.5_minDf=1....  0.6097\n",
       "10  topics=75_maxFeatures=12000_maxDf=0.6_minDf=1....  0.6109\n",
       "11  topics=75_maxFeatures=16000_maxDf=0.4_minDf=1....  0.6047\n",
       "12  topics=75_maxFeatures=16000_maxDf=0.5_minDf=1....  0.6143\n",
       "13  topics=100_maxFeatures=12000_maxDf=0.4_minDf=1...  0.6269"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result['lda model'] = [lda_lst[i][11:] for i in range(len(lda_lst))]\n",
    "result['acc'] = acc_lst\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more topics, less maxFeatures performs better"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
